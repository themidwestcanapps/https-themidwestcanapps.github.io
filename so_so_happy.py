# -*- coding: utf-8 -*-
"""so_so_Happy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ADo0LbtUccHpqyQ1tJHa-9a_5uEN9WQR
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install musdb
# !pip install norbert
# !pip install librosa
# !pip install youtube-dl
# !git clone https://github.com/sigsep/open-unmix-pytorch.git



import torch
import librosa
import youtube_dl
import os
import soundfile as sf
from google.colab import files
from IPython.display import Audio, display

use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")

# Commented out IPython magic to ensure Python compatibility.
# %cd open-unmix-pytorch/
import test

# import musdb
# mus = musdb.DB(download=True, subsets='test')

# track = mus[49]
# print(track.name)
# display(Audio(track.audio.T, rate=track.rate))



# estimates = test.separate(
#     audio=track.audio, 
#     targets=['vocals', 'drums', 'bass', 'other'], 
#     residual_model=False,
#     niter=1,
#     device=device
# )
# for target, estimate in estimates.items():
#     print(target)
#     display(Audio(estimate.T, rate=track.rate))

# estimates = test.separate(
#     audio=track.audio, 
#     targets=['vocals'], 
#     residual_model=True,
#     device=device
# )
# for target, estimate in estimates.items():
#     print(target)
#     display(Audio(estimate.T, rate=track.rate))

# estimates = test.separate(
#     audio=track.audio, 
#     targets=['vocals', 'drums', 'bass', 'other'], 
#     residual_model=True,
#     device=device
# )
# print('vocals')
# display(Audio(estimates['vocals'].T, rate=track.rate))
# acc = np.sum(
#     [audio for target, audio in estimates.items() if not target=='vocals'],
#     axis=0
# )
# print('accompaniment')
# display(Audio(acc.T, rate=track.rate))

from IPython.display import HTML
url = "Hwg7hJrDiRg"
start = 1
stop = 30
embed_url = "https://www.youtube.com/embed/%s?rel=0&start=%d&end=%d&amp;controls=0&amp;showinfo=0" % (url, start, stop)
HTML('<iframe width="560" height="350" src=' + embed_url + 'frameborder="0" allowfullscreen></iframe>')

# from IPython.display import HTML
# url = "56-JEHWfrfI" #@param {type:"string"}
# start =  30#@param {type:"number"}
# stop =  90#@param {type:"number"}
# embed_url = "https://www.youtube.com/embed/%s?rel=0&start=%d&end=%d&amp;controls=0&amp;showinfo=0" % (url, start, stop)
# HTML('<iframe width="560" height="350" src=' + embed_url + 'frameborder="0" allowfullscreen></iframe>')

def my_hook(d):
    if d['status'] == 'finished':
        print('Done downloading...')


ydl_opts = {
    'format': 'bestaudio/best',
    'postprocessors': [{
        'key': 'FFmpegExtractAudio',
        'preferredcodec': 'wav',
        'preferredquality': '44100',
    }],
    'outtmpl': '%(title)s.wav',
    'progress_hooks': [my_hook],
}
with youtube_dl.YoutubeDL(ydl_opts) as ydl:
    info = ydl.extract_info(url, download=False)
    status = ydl.download([url])

audio, rate = librosa.load(info.get('title', None) + '.wav', sr=44100, mono=False)
audio = audio[:, start*rate:stop*rate]
print(audio.shape)
display(Audio(audio, rate=rate))
estimates = test.separate(audio=audio.T, targets=['drums', 'bass', 'vocals', 'other'], device=device, residual_model=True)
for target, estimate in estimates.items():
    print(target)
    display(Audio(estimate.T, rate=rate))

for target, estimate in estimates.items():
    sf.write(target + '.wav', estimate, 44100, subtype='PCM_16')
    files.download(target + '.wav')

!pip install --upgrade PyOgg

!pip install --upgrade soundfile

# Commented out IPython magic to ensure Python compatibility.
!git clone -l -s git://github.com/themidwestcanapps/SoundFile.git clonded-repo
# %cd cloned-repo
!ls

import IPython
IPython.display.Audio('/content/flume_0-30_vocals.wav')

import soundfile as sf

data, samplerate = sf.read('/content/flume_0-30_vocals.wav')

data

data.shape

import numpy as np
np.savetxt('foo.csv', data, delimiter=",", )

import pandas as pd

l7 = pd.read_csv('foo.csv', skiprows=-2)

l7.shape

pd.DataFrame(data).to_csv("flume_vocal.csv")

df_ll7 = pd.read_csv('flume_vocal.csv', delimiter=None, names='in', skiprows=None,
                     index_col=None)

df_ll7



samplerate

data, samplerate = sf.read('stereo_file.wav')

data

new_data = dict(data)

new_data

sf.write('new_xx_sa.flac', data, samplerate)

import numpy as np
import soundfile as sf
sf.write('stereo_file.wav', np.random.randn(10, 2), 44100, 'PCM_24')

rms = [np.sqrt(np.mean(block**2)) for block in
        sf.blocks('bass.wav', blocksize=1024, overlap=512)]

rms





import numpy as np 
import librosa, librosa.display 
import matplotlib.pyplot as plt

plt.rcParams['agg.path.chunksize'] = 100000

display(Audio(audio, rate=rate))

FIG_SIZE = (15,10)

file = 

signal, sample_rate = librosa.load(file, sr=22050)

plt.figure(figsize=FIG_SIZE)
librosa.display.waveplot(signal, sample_rate, alpha=0.4)
plt.xlabel("Time (s)")
plt.ylabel("AMpliTude")
plt.title("WaveForm")



f 'Accept: application/vnd.github.v3.raw' \
     --location https://raw.githubusercontent.com/themidwestcanapps/https-themidwestcanapps.github.io/master/7.4cc_signal_sep.wavo

!curl --remote-name \
     -H 'Accept: application/vnd.github.v3.raw' \
     --location https://raw.githubusercontent.com/themidwestcanapps/https-themidwestcanapps.github.io/master/7.4cc_signal_sep.wav

data, samplerate = sf.read('7.4cc_signal_sep.wav')
sf.write('cc.wav', data, samplerate)

go_go = sf.write('cc.wav', data, samplerate)

import os

sounder = os.system('7.4cc_signal_sep.wav')

!pip install pydub

plus = data, samplerate

from pydub import AudioSegment

song = AudioSegment.from_wav("7.4cc_signal_sep.wav")
song.export("final.wav", format="wav")





# from google.colab import drive
# drive.mount('/content/drive')

# uploaded = drive.mount('/content/drive/03 Cookies & Cream.m4a')?



start = 0 #@param {type:"number"}
stop = 15 #@param {type:"number"}
audio, rate = librosa.load(
    list(.keys())[0],
    sr=44100,
    offset=start,
    duration=stop-start,
    mono=False
)
display(Audio(audio, rate=rate))
estimates = test.separate(
    audio=audio.T,
    targets=['vocals', 'drums', 'bass', 'other'],
    residual_model=False,
    device=device,
    niter=1
)
for target, estimate in estimates.items():
    print(target)
    display(Audio(estimate.T, rate=rate))

import IPython.display as ipd
ll7= ipd.Audio(filename='7.4cc_signal_sep.wav')

for target, estimate in estimates.items():
    sf.write(target + '.wav', estimate, 44100, subtype='PCM_16')
    files.download(target + '.wav')

import stempeg
S = np.array([array for array in estimates.values()])
stempeg.write_stems(S, "umx.stem.m4a", rate=44100)
files.download("umx.stem.m4a")

